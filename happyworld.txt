You may have tables in your Amazon Redshift data warehouse or in your Amazon Simple Storage Service (Amazon S3) data lake full of records containing customer case notes, product reviews, and social media messages, in many languages. Your task is to identify the products that people are talking about, determine if they’re expressing happy thoughts or sad thoughts, translate their comments into a single common language, and create copies of the data for your business analysts with this new information added to each record. Additionally, you need to remove any personally identifiable information (PII), such as names, addresses, and credit card numbers.

You already know how to use Amazon Redshift to transform data using simple SQL commands and built-in functions. Now you can also use Amazon Redshift to translate, analyze, and redact text fields, thanks to Amazon Translate, Amazon Comprehend, and the power of Amazon Redshift supported AWS Lambda user-defined functions (UDFs).



With Amazon Redshift, you can query and combine structured and semi-structured data across your data warehouse, operational database, and data lake using standard SQL. Amazon Comprehend is a natural language processing (NLP) service that makes it easy to uncover insights from text. Amazon Translate is a neural machine translation service that delivers fast, high-quality, affordable, and customizable language translation. In this post, I show you how you can now use them together to perform the following actions:

Detect and redact PII
Detect and redact entities (such as items, places, or quantities)
Detect the dominant language of a text field
Detect the prevailing sentiment expressed—positive, negative, neither, or both
Translate text from one language to another
This post accomplishes the following goals:

Show you how to quickly set up the Amazon Redshift text analytics functions in your own AWS account (it’s fast and easy!)
Briefly explain how the functions work
Discuss performance and cost
Provide a tutorial where we do some text analytics on Amazon product reviews
Describe all the available functions
We include a list of all the available functions at the end of the post; the following code shows a few example queries and results:

SELECT f_detect_sentiment('I am very happy', 'en') as sentiment
sentiment
POSITIVE

SELECT f_detect_pii_entities('I am Bob, I live in Herndon VA, and I love cars', 'en') as pii
pii
[["NAME","Bob"],["ADDRESS","Herndon VA"]]

SELECT f_redact_pii_entities('I am Bob, I live in Herndon VA, and I love cars', 'en', 'NAME,ADDRESS') as pii_redacted
pii_redacted
I am [NAME], I live in [ADDRESS], and I love cars

SELECT f_translate_text('It is a beautiful day in the neighborhood', 'auto', 'fr', 'null') as translated_text
translated_text
C'est une belle journée dans le quartier
Prerequisites
If you’re new to Amazon Redshift, review the Getting Started guide to set up your cluster and SQL client.

Install the text analytics UDF
An Amazon Redshift UDF uses Lambda to implement the function capability. I discuss more details later in this post, but you don’t need to understand the inner workings to use the text analytics UDF, so let’s get started.

Install the prebuilt Lambda function with the following steps:

Navigate to the RedshiftTextAnalyticsUDF application in the AWS Serverless Application Repository.
In the Application settings section, keep the settings at their defaults.
Select I acknowledge that this app creates custom IAM roles.
Choose Deploy.

When the application has deployed, choose the application Deployments tab and then CloudFormation stack.

Choose the stack Outputs tab.

Select the ARN that is shown as the value of the output labeled RedshiftLambdaInvokeRole and copy to the clipboard.
On the Amazon Redshift console, in the navigation menu, choose CLUSTERS, then choose the name of the cluster that you want to update.
For Actions, choose Manage IAM roles.
Choose Enter ARN and enter the ARN for the role that you copied earlier.
Choose Associate IAM role to add it to the list of Attached IAM roles.
Choose Save changes to associate the IAM role with the cluster.
Select the SQL code that is shown as the value of the output labeled SQLScriptExternalFunction and copy to the clipboard.

Paste this SQL into your SQL client, and run it on your Amazon Redshift database as an admin user.

And that’s it! Now you have a suite of new Lambda backed text analytics functions. You’re ready to try some text analytics queries in Amazon Redshift.

If you prefer to build and deploy from the source code instead, see the directions in the GitHub repository README.

Run your first text analytics query
Enter the following query into the SQL editor:

SELECT f_detect_sentiment('I am very happy', 'en') as sentiment
You get a simple POSITIVE result. Now try again, varying the input text—try something less positive to see how the returned sentiment value changes.

To get the sentiment along with confidence scores for each potential sentiment value, use the following query instead:

SELECT f_detect_sentiment_all('I am very happy', 'en') as sentiment
Now you get a JSON string containing the sentiment and all the sentiment scores:

{"sentiment":"POSITIVE","sentimentScore":{"positive":0.999519,"negative":7.407639E-5,"neutral":2.7478999E-4,"mixed":1.3210243E-4}}
You can use the built-in support in Amazon Redshift for semi-structured data on this result to extract the fields for further analysis. For more information, see Ingesting and querying semistructured data in Amazon Redshift. I show you examples later in this post.

How the UDF works
For more information about the Amazon Redshift UDF framework, see Creating a scalar Lambda UDF.

The Java class TextAnalyticsUDFHandler implements the core logic for each of our UDF Lambda function handlers. Each text analytics function has a corresponding public method in this class.

Amazon Redshift invokes our UDF Lambda function with batches of input records. The TextAnalyticsUDFHandler subdivides these batches into smaller batches of up to 25 rows to take advantage of the Amazon Comprehend synchronous multi-document batch APIs where they are available (for example, for detecting language, entities, and sentiment). When no synchronous multi-document API is available (such as for DetectPiiEntity and TranslateText), we use the single-document API instead.

Amazon Comprehend API service quotas provide guardrails to limit your cost exposure from unintentional high usage (we discuss this more in the following section). By default, the multi-document batch APIs process up to 250 records per second, and the single-document APIs process up to 20 records per second. Our UDFs use exponential backoff and retry to throttle the request rate to stay within these limits. You can request increases to the transactions per second quota for APIs using the Quota Request Template on the AWS Management Console.

Amazon Comprehend and Amazon Translate each enforce a maximum input string length of 5,000 utf-8 bytes. Text fields that are longer than 5,000 utf-8 bytes are truncated to 5,000 bytes for language and sentiment detection, and split on sentence boundaries into multiple text blocks of under 5,000 bytes for translation and entity or PII detection and redaction. The results are then combined.

Optimize cost
In addition to Amazon Redshift costs, the text analytics UDFs incur usage costs from Lambda, Amazon Comprehend, and Amazon Translate. The amount you pay is a factor of the total number of records and characters that you process with the UDFs. For more information, see AWS Lambda pricing, Amazon Comprehend pricing, and Amazon